{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6bd80a0883591efded4260a5991bd57e",
     "grade": false,
     "grade_id": "cell-c9581b6ad17b53d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For this problem set, we'll be using the Jupyter notebook:\n",
    "\n",
    "![](jupyter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2c5c0ea232af7dcfe11b8cb4f8a99495",
     "grade": false,
     "grade_id": "cell-1b0c57d4df18a1e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Mllib exercises\n",
    "\n",
    "In this notebook you will implement multiple small methods that are used to predict if a customer is going to be a `paid_customer`. We use logistic regression (https://en.wikipedia.org/wiki/Logistic_regression) for solving the classification problem.\n",
    "\n",
    "We will use a sample of data from http://cs.hut.fi/u/arasalo1/resources/osge_pool-1-thread-1.data.zip.\n",
    "\n",
    "Your task is to create a machine learning pipeline that transform the data so that mllib's logistic regression can make predictions on if a customer is going to pay for the service. First method `convert` transforms the file into a dataframe so that it is easier to process. Categorical features are transformed using method `indexer`. `featureAssembler` creates a single feature vector. Most mllib's machine learning algorithms require this. `scaler` scales the variables. `createModel`creates and trains the logistic regression model. Training data has been transformed properly using the previous methods. Finally, `predict` is used to make predictions whether the user is a paying customer using the trained model.\n",
    "\n",
    "Note: try to avoid additional imports as it can cause problems with server tests.\n",
    "\n",
    "### Data schema\n",
    "\n",
    "| column_header | type |description |\n",
    "| :------------- | :--- | :----------- |\n",
    "| cid | uuid | customer id |\n",
    "| cname | string | name of the user |\n",
    "| email | string | email address of the user |\n",
    "| gender | string | customer's gender |\n",
    "| age | int | age of the customer |\n",
    "| address | string | user provided address during registration, stores only US based addresses other countries gets 'N/A' |\n",
    "| country | string | country to which customer belongs to |\n",
    "| register_date | long | date on which user registered with us in milliseconds |\n",
    "| friend_count | int | number of friends a user has |\n",
    "| lifetime | int | number of days a user has been active since registration date |\n",
    "| citygame_played | int | number of times citygame has been played by user |\n",
    "| pictionarygame_played | int | number of times pictionary game has been played by user |\n",
    "| scramblegame_played | int | number of times scaramble game has been played by user |\n",
    "| snipergame_played | int | number of times sniper game has been played by user |\n",
    "| revenue | int | revenue generated by the user |\n",
    "| paid_subscriber | string | whether the customer is paid customer or not, represented by `yes` or `no` |\n",
    "\n",
    "\n",
    "Use Spark machine learning library mllib's Binomial Logistic Regression algorithm.  \n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression\n",
    "\n",
    "Use these features for training your model:\n",
    "* gender \n",
    "* age\n",
    "* country\n",
    "* friend_count\n",
    "* lifetime\n",
    "* citygame_played\n",
    "* pictionarygame_played\n",
    "* scramblegame_played\n",
    "* snipergame_played\n",
    "* paid_subscriber(this is the feature to predict)\n",
    "\n",
    "The data contains categorical features, so you need to change them accordingly.  \n",
    "https://spark.apache.org/docs/latest/ml-features.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "157152d64c0d96fd0e8133829939e327",
     "grade": false,
     "grade_id": "cell-0f850f2cc2f99366",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"gaming\")\\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\")\\\n",
    "    .config(\"spark.shuffle.service.enabled\", \"true\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sampleDataPath = \"testData.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57c990210ca3df112d8d715e7d39fb6b",
     "grade": false,
     "grade_id": "cell-a27d59b341ba3a5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Generate random sample\n",
    "import random\n",
    "\n",
    "randomData = \"randomsample.data\"\n",
    "\n",
    "with open(sampleDataPath) as sampleFile:\n",
    "    lines = random.sample(sampleFile.readlines(), 4000)\n",
    "\n",
    "outF = open(randomData, \"w\")\n",
    "outF.writelines(lines)\n",
    "outF.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b03034f1da4fbdc1471eedf4f8a8dd7",
     "grade": false,
     "grade_id": "cell-d62a1aad5888f54b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Convert\n",
    "`convert` creates a dataframe, removes unnecessary colums and converts the rest to right format.   \n",
    "Data schema:\n",
    "* gender: Double (1 if male else 0)\n",
    "* age: Double\n",
    "* country: String\n",
    "* friend_count: Double\n",
    "* lifetime: Double\n",
    "* game1: Double (citygame_played)\n",
    "* game2: Double (pictionarygame_played)\n",
    "* game3: Double (scramblegame_played)\n",
    "* game4: Double (snipergame_played)\n",
    "* paid_customer: Double (1 if yes else 0)  \n",
    "\n",
    "The function already creates a SQL table called \"gaming\", your job is to remove unneccesary columns and convert the rest to right format. Hint: SQL `SELECT` query and `CAST`. You will also need to use `IF` to properly parse and read some of the variables. e.g. `IF(gender='male',1,0)`.\n",
    "\n",
    "param `path`: path to file  \n",
    "`return`: converted DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab0486c9dea6471e8b45c2e96f2568c4",
     "grade": false,
     "grade_id": "cell-0f036589fc66950b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert(path):\n",
    "    originalCols = StructType([\\\n",
    "    StructField(\"session_id\", StringType(),False),\\\n",
    "    StructField(\"cname\", StringType(),False),\\\n",
    "    StructField(\"email\",StringType(),False),\\\n",
    "    StructField(\"gender\",StringType(),False),\\\n",
    "    StructField(\"age\",DoubleType(),False),\\\n",
    "    StructField(\"address\",StringType(),False),\\\n",
    "    StructField(\"country\",StringType(),True),\\\n",
    "    StructField(\"register_date\",StringType(),False),\\\n",
    "    StructField(\"friend_count\",DoubleType(),False),\\\n",
    "    StructField(\"lifetime\",DoubleType(),False),\\\n",
    "    StructField(\"game1\",DoubleType(),False),\\\n",
    "    StructField(\"game2\",DoubleType(),False),\\\n",
    "    StructField(\"game3\",DoubleType(),False),\\\n",
    "    StructField(\"game4\",DoubleType(),False),\\\n",
    "    StructField(\"revenue\",DoubleType(),False),\\\n",
    "    StructField(\"paid_customer\",StringType(),False)])\n",
    "    data = spark.read.option(\"header\",\"false\").schema(originalCols).csv(path)\n",
    "    data.createOrReplaceTempView(\"gaming\")\n",
    "    \n",
    "    d = spark.sql('''\n",
    "    \n",
    "    Select CAST(IF(gender = 'male' , 1 , 0) AS DOUBLE) as gender,\n",
    "    CAST(age as DOUBLE) , CAST(country AS STRING)  ,\n",
    "    CAST(friend_count AS DOUBLE) , CAST(lifetime AS DOUBLE) , \n",
    "    CAST(game1 AS DOUBLE) ,\n",
    "    CAST(game2 AS DOUBLE),\n",
    "    CAST(game3 AS DOUBLE),\n",
    "    CAST(game4 AS DOUBLE),\n",
    "    CAST(IF(paid_customer = 'yes' , 1 , 0) AS DOUBLE) as paid_customer \n",
    "    FROM gaming\n",
    "    \n",
    "    ''')\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ceeaec6438fdc3973382f57a6bed13e",
     "grade": false,
     "grade_id": "cell-c5fe0802b37f6d1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+\n",
      "|gender| age|country|friend_count|lifetime|game1|game2|game3|game4|paid_customer|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+\n",
      "|   1.0|23.0|    USA|         0.0|     5.0|  0.0|  1.0|  1.0|  3.0|          0.0|\n",
      "|   1.0|20.0|     UK|         2.0|     4.0|  0.0|  0.0|  0.0|  4.0|          0.0|\n",
      "|   1.0|24.0|     UK|         9.0|    13.0|  1.0|  0.0|  2.0| 10.0|          0.0|\n",
      "|   1.0|21.0|    USA|       412.0|    80.0|  8.0|  7.0| 17.0| 48.0|          1.0|\n",
      "|   1.0|20.0|    USA|         0.0|    38.0|  0.0|  3.0|  6.0| 29.0|          0.0|\n",
      "|   0.0|22.0| FRANCE|        86.0|     2.0|  0.0|  2.0|  0.0|  0.0|          0.0|\n",
      "|   1.0|27.0|GERMANY|         2.0|     5.0|  1.0|  1.0|  1.0|  2.0|          0.0|\n",
      "|   0.0|30.0|    USA|         0.0|    45.0| 19.0| 21.0|  3.0|  2.0|          0.0|\n",
      "|   0.0|26.0|GERMANY|         7.0|    20.0|  6.0|  8.0|  5.0|  1.0|          0.0|\n",
      "|   0.0|18.0|     UK|         0.0|     7.0|  5.0|  2.0|  0.0|  0.0|          0.0|\n",
      "|   1.0|22.0|    USA|         0.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|\n",
      "|   1.0|24.0|GERMANY|       417.0|     1.0|  0.0|  0.0|  0.0|  1.0|          0.0|\n",
      "|   0.0|21.0|    USA|         3.0|     3.0|  2.0|  1.0|  0.0|  0.0|          0.0|\n",
      "|   1.0|18.0|    USA|         8.0|     1.0|  0.0|  0.0|  0.0|  1.0|          0.0|\n",
      "|   0.0|23.0|    USA|         7.0|     8.0|  4.0|  2.0|  2.0|  0.0|          0.0|\n",
      "|   1.0|22.0|     UK|        60.0|     8.0|  0.0|  0.0|  4.0|  4.0|          0.0|\n",
      "|   1.0|18.0|    USA|         3.0|     7.0|  0.0|  2.0|  1.0|  4.0|          0.0|\n",
      "|   0.0|20.0| CANADA|         0.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|\n",
      "|   1.0|22.0|    USA|         5.0|    83.0|  6.0|  9.0| 10.0| 58.0|          0.0|\n",
      "|   1.0|23.0|    USA|       351.0|     5.0|  0.0|  0.0|  0.0|  5.0|          0.0|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = convert(sampleDataPath)\n",
    "data.cache()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca92a0d8e3cdd302cc188f1ed99be75f",
     "grade": true,
     "grade_id": "cell-adf9a5c07d840635",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''convert tests'''\n",
    "correctCols = StructType([\\\n",
    "StructField(\"gender\",DoubleType(),False),\\\n",
    "StructField(\"age\",DoubleType(),True),\\\n",
    "StructField(\"country\",StringType(),True),\\\n",
    "StructField(\"friend_count\",DoubleType(),True),\\\n",
    "StructField(\"lifetime\",DoubleType(),True),\\\n",
    "StructField(\"game1\",DoubleType(),True),\\\n",
    "StructField(\"game2\",DoubleType(),True),\\\n",
    "StructField(\"game3\",DoubleType(),True),\\\n",
    "StructField(\"game4\",DoubleType(),True),\\\n",
    "StructField(\"paid_customer\",DoubleType(),False)])\n",
    "\n",
    "fakeData = [(0.0,1.0,\"A\",1.0,1.0,1.0,1.0,1.0,1.0,0.0)]\n",
    "\n",
    "fakeDf = spark.createDataFrame(fakeData, correctCols)\n",
    "\n",
    "assert data.dtypes == fakeDf.dtypes, \"the schema was expected to be %s but it was %s\" % (fakeDf.dtypes, data.dtypes)\n",
    "\n",
    "test1 = str(data.sample(False, 0.01, seed=12345).limit(1).first())\n",
    "correct1 = \"Row(gender=1.0, age=20.0, country='UK', friend_count=2.0, lifetime=4.0, game1=0.0, game2=0.0, game3=0.0, game4=4.0, paid_customer=0.0)\"\n",
    "assert test1 == correct1, \"the row was expected to be %s but it was %s\" % (correct1, test1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d9efd0f2d7b3c9c90c3e1e53f1f8b1f",
     "grade": false,
     "grade_id": "cell-0a958c2ac19966e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Indexer\n",
    "`indexer` converts categorical features into doubles.  \n",
    "https://spark.apache.org/docs/latest/ml-features.html#stringindexer  \n",
    "`country` is the only categorical feature.  \n",
    "After these modifications schema should be:\n",
    "  * gender: Double (1 if male else 0)\n",
    "  * age: Double\n",
    "  * country: String\n",
    "  * friend_count: Double\n",
    "  * lifetime: Double\n",
    "  * game1: Double (citygame_played)\n",
    "  * game2: Double (pictionarygame_played)\n",
    "  * game3: Double (scramblegame_played)\n",
    "  * game4: Double (snipergame_played)\n",
    "  * paid_customer: Double (1 if yes else 0)\n",
    "  * country_index: Double\n",
    "  \n",
    "param `df`: DataFrame  \n",
    "`return`: transformed Dataframe. The returned dataframe should have a new column called \"country_index\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b9edd4a131d93cbec033dcaf5117b13",
     "grade": false,
     "grade_id": "cell-2bacebf519b88b19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def indexer(df):\n",
    "    indexer = StringIndexer(inputCol=\"country\", outputCol=\"country_index\")\n",
    "    indexed = indexer.fit(df).transform(df)\n",
    "    return indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfd1d3b51ffb333a0d5989c12947af28",
     "grade": false,
     "grade_id": "cell-67800749e92168d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+\n",
      "|gender| age|country|friend_count|lifetime|game1|game2|game3|game4|paid_customer|country_index|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+\n",
      "|   1.0|23.0|    USA|         0.0|     5.0|  0.0|  1.0|  1.0|  3.0|          0.0|          0.0|\n",
      "|   1.0|20.0|     UK|         2.0|     4.0|  0.0|  0.0|  0.0|  4.0|          0.0|          1.0|\n",
      "|   1.0|24.0|     UK|         9.0|    13.0|  1.0|  0.0|  2.0| 10.0|          0.0|          1.0|\n",
      "|   1.0|21.0|    USA|       412.0|    80.0|  8.0|  7.0| 17.0| 48.0|          1.0|          0.0|\n",
      "|   1.0|20.0|    USA|         0.0|    38.0|  0.0|  3.0|  6.0| 29.0|          0.0|          0.0|\n",
      "|   0.0|22.0| FRANCE|        86.0|     2.0|  0.0|  2.0|  0.0|  0.0|          0.0|          3.0|\n",
      "|   1.0|27.0|GERMANY|         2.0|     5.0|  1.0|  1.0|  1.0|  2.0|          0.0|          2.0|\n",
      "|   0.0|30.0|    USA|         0.0|    45.0| 19.0| 21.0|  3.0|  2.0|          0.0|          0.0|\n",
      "|   0.0|26.0|GERMANY|         7.0|    20.0|  6.0|  8.0|  5.0|  1.0|          0.0|          2.0|\n",
      "|   0.0|18.0|     UK|         0.0|     7.0|  5.0|  2.0|  0.0|  0.0|          0.0|          1.0|\n",
      "|   1.0|22.0|    USA|         0.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|          0.0|\n",
      "|   1.0|24.0|GERMANY|       417.0|     1.0|  0.0|  0.0|  0.0|  1.0|          0.0|          2.0|\n",
      "|   0.0|21.0|    USA|         3.0|     3.0|  2.0|  1.0|  0.0|  0.0|          0.0|          0.0|\n",
      "|   1.0|18.0|    USA|         8.0|     1.0|  0.0|  0.0|  0.0|  1.0|          0.0|          0.0|\n",
      "|   0.0|23.0|    USA|         7.0|     8.0|  4.0|  2.0|  2.0|  0.0|          0.0|          0.0|\n",
      "|   1.0|22.0|     UK|        60.0|     8.0|  0.0|  0.0|  4.0|  4.0|          0.0|          1.0|\n",
      "|   1.0|18.0|    USA|         3.0|     7.0|  0.0|  2.0|  1.0|  4.0|          0.0|          0.0|\n",
      "|   0.0|20.0| CANADA|         0.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|          4.0|\n",
      "|   1.0|22.0|    USA|         5.0|    83.0|  6.0|  9.0| 10.0| 58.0|          0.0|          0.0|\n",
      "|   1.0|23.0|    USA|       351.0|     5.0|  0.0|  0.0|  0.0|  5.0|          0.0|          0.0|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed = indexer(data)\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cad0eb29ea5e1718b2a6f3d64e912f7b",
     "grade": true,
     "grade_id": "cell-ee803468a162e783",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''indexer tests'''\n",
    "correctCols = StructType([\\\n",
    "StructField(\"gender\",DoubleType(),False),\\\n",
    "StructField(\"age\",DoubleType(),False),\\\n",
    "StructField(\"country\",StringType(),True),\\\n",
    "StructField(\"friend_count\",DoubleType(),False),\\\n",
    "StructField(\"lifetime\",DoubleType(),False),\\\n",
    "StructField(\"game1\",DoubleType(),False),\\\n",
    "StructField(\"game2\",DoubleType(),False),\\\n",
    "StructField(\"game3\",DoubleType(),False),\\\n",
    "StructField(\"game4\",DoubleType(),False),\\\n",
    "StructField(\"paid_customer\",DoubleType(),False),\\\n",
    "StructField(\"country_index\",DoubleType(),False)])\n",
    "\n",
    "fakeData = [(0.0,1.0,\"A\",1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0)]\n",
    "\n",
    "fakeDf = spark.createDataFrame(fakeData, correctCols)\n",
    "\n",
    "assert indexed.dtypes == fakeDf.dtypes, \"the schema was expected to be %s but it was %s\" % (fakeDf.dtypes, indexed.dtypes)\n",
    "\n",
    "test2 = str(indexed.sample(False, 0.01, seed=12345).limit(1).first())\n",
    "correct2 = \"Row(gender=1.0, age=20.0, country='UK', friend_count=2.0, lifetime=4.0, game1=0.0, game2=0.0, game3=0.0, game4=4.0, paid_customer=0.0, country_index=1.0)\"\n",
    "assert test2 == correct2, \"the row was expected to be %s but it was %s\" % (correct2, test2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f32c0330d80068b2e71ca400c4fba79",
     "grade": false,
     "grade_id": "cell-cf5d55641055bd63",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Feature Assembler\n",
    "`featureAssembler` combines features into one vector. Most mllib algorithms require this step.  \n",
    "https://spark.apache.org/docs/latest/ml-features.html#vectorassembler  \n",
    "In this task your vector assembler should take and combine the following columns in the same order listed:  \n",
    "```[\"gender\", \"age\",\"friend_count\",\"lifetime\",\"game1\",\"game2\",\"game3\",\"game4\",\"country_index\"]```.  \n",
    "\n",
    "param `df`: Dataframe that is transformed using indexer  \n",
    "`return` transformed Dataframe. The returned dataframe should have a new column called \"features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a64089df33960fc9596c3180a60c73e",
     "grade": false,
     "grade_id": "cell-6ad1d748f9da8a8a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def featureAssembler(df):\n",
    "    \n",
    "    assembler = VectorAssembler(\n",
    "    inputCols=[\"gender\", \"age\",\"friend_count\",\"lifetime\",\"game1\",\"game2\",\"game3\",\"game4\",\"country_index\"],\n",
    "    outputCol=\"features\")\n",
    "    output = assembler.transform(df)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adc6b61bd8cceeafc5ce8ecf1ff7aef2",
     "grade": false,
     "grade_id": "cell-66f4b261a69b9cd9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+\n",
      "|gender| age|country|friend_count|lifetime|game1|game2|game3|game4|paid_customer|country_index|            features|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+\n",
      "|   1.0|23.0|    USA|         0.0|     5.0|  0.0|  1.0|  1.0|  3.0|          0.0|          0.0|[1.0,23.0,0.0,5.0...|\n",
      "|   1.0|20.0|     UK|         2.0|     4.0|  0.0|  0.0|  0.0|  4.0|          0.0|          1.0|[1.0,20.0,2.0,4.0...|\n",
      "|   1.0|24.0|     UK|         9.0|    13.0|  1.0|  0.0|  2.0| 10.0|          0.0|          1.0|[1.0,24.0,9.0,13....|\n",
      "|   1.0|21.0|    USA|       412.0|    80.0|  8.0|  7.0| 17.0| 48.0|          1.0|          0.0|[1.0,21.0,412.0,8...|\n",
      "|   1.0|20.0|    USA|         0.0|    38.0|  0.0|  3.0|  6.0| 29.0|          0.0|          0.0|[1.0,20.0,0.0,38....|\n",
      "|   0.0|22.0| FRANCE|        86.0|     2.0|  0.0|  2.0|  0.0|  0.0|          0.0|          3.0|[0.0,22.0,86.0,2....|\n",
      "|   1.0|27.0|GERMANY|         2.0|     5.0|  1.0|  1.0|  1.0|  2.0|          0.0|          2.0|[1.0,27.0,2.0,5.0...|\n",
      "|   0.0|30.0|    USA|         0.0|    45.0| 19.0| 21.0|  3.0|  2.0|          0.0|          0.0|[0.0,30.0,0.0,45....|\n",
      "|   0.0|26.0|GERMANY|         7.0|    20.0|  6.0|  8.0|  5.0|  1.0|          0.0|          2.0|[0.0,26.0,7.0,20....|\n",
      "|   0.0|18.0|     UK|         0.0|     7.0|  5.0|  2.0|  0.0|  0.0|          0.0|          1.0|[0.0,18.0,0.0,7.0...|\n",
      "|   1.0|22.0|    USA|         0.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|          0.0|(9,[0,1],[1.0,22.0])|\n",
      "|   1.0|24.0|GERMANY|       417.0|     1.0|  0.0|  0.0|  0.0|  1.0|          0.0|          2.0|[1.0,24.0,417.0,1...|\n",
      "|   0.0|21.0|    USA|         3.0|     3.0|  2.0|  1.0|  0.0|  0.0|          0.0|          0.0|[0.0,21.0,3.0,3.0...|\n",
      "|   1.0|18.0|    USA|         8.0|     1.0|  0.0|  0.0|  0.0|  1.0|          0.0|          0.0|[1.0,18.0,8.0,1.0...|\n",
      "|   0.0|23.0|    USA|         7.0|     8.0|  4.0|  2.0|  2.0|  0.0|          0.0|          0.0|[0.0,23.0,7.0,8.0...|\n",
      "|   1.0|22.0|     UK|        60.0|     8.0|  0.0|  0.0|  4.0|  4.0|          0.0|          1.0|[1.0,22.0,60.0,8....|\n",
      "|   1.0|18.0|    USA|         3.0|     7.0|  0.0|  2.0|  1.0|  4.0|          0.0|          0.0|[1.0,18.0,3.0,7.0...|\n",
      "|   0.0|20.0| CANADA|         0.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|          4.0|(9,[1,8],[20.0,4.0])|\n",
      "|   1.0|22.0|    USA|         5.0|    83.0|  6.0|  9.0| 10.0| 58.0|          0.0|          0.0|[1.0,22.0,5.0,83....|\n",
      "|   1.0|23.0|    USA|       351.0|     5.0|  0.0|  0.0|  0.0|  5.0|          0.0|          0.0|[1.0,23.0,351.0,5...|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembled = featureAssembler(indexed)\n",
    "assembled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "559ef0cb83574567917cb396bc19d12a",
     "grade": true,
     "grade_id": "cell-72527054a3bfbb12",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''assembler schema test'''\n",
    "from pyspark.ml.linalg import *\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "\n",
    "correctCols = StructType([\\\n",
    "StructField(\"gender\",DoubleType(),False),\\\n",
    "StructField(\"age\",DoubleType(),False),\\\n",
    "StructField(\"country\",StringType(),True),\\\n",
    "StructField(\"friend_count\",DoubleType(),False),\\\n",
    "StructField(\"lifetime\",DoubleType(),False),\\\n",
    "StructField(\"game1\",DoubleType(),False),\\\n",
    "StructField(\"game2\",DoubleType(),False),\\\n",
    "StructField(\"game3\",DoubleType(),False),\\\n",
    "StructField(\"game4\",DoubleType(),False),\\\n",
    "StructField(\"paid_customer\",DoubleType(),False),\\\n",
    "StructField(\"country_index\",DoubleType(),False),\\\n",
    "StructField(\"features\", VectorUDT(),True)])\n",
    "\n",
    "fakeData = [(0.0,1.0,\"A\",1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,(Vectors.dense([1.0, 2.0])))]\n",
    "\n",
    "fakeDf = spark.createDataFrame(fakeData, correctCols)\n",
    "\n",
    "assert assembled.dtypes == fakeDf.dtypes, \"the schema was expected to be %s but it was %s\" % (fakeDf.dtypes, assembled.dtypes)\n",
    "\n",
    "test3 = str(assembled.sample(False, 0.01, seed=12345).limit(1).first())\n",
    "correct3 = \"Row(gender=1.0, age=20.0, country='UK', friend_count=2.0, lifetime=4.0, game1=0.0, game2=0.0, game3=0.0, game4=4.0, paid_customer=0.0, country_index=1.0, features=DenseVector([1.0, 20.0, 2.0, 4.0, 0.0, 0.0, 0.0, 4.0, 1.0]))\"\n",
    "assert test3 == correct3, \"the row was expected to be %s but it was %s\" % (correct3, test3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97917f83fd493732474d0950432b4271",
     "grade": false,
     "grade_id": "cell-c1ce008f100710a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Scaler\n",
    "`scaler` standardizes data to improve performance.  \n",
    "https://spark.apache.org/docs/latest/ml-features.html#standardscaler  \n",
    "For this task please remember to set the `withStd` and `withMean` parameters to true.\n",
    "\n",
    "param `df` Dataframe that is transformed using featureAssembler  \n",
    "param `outputColName` name of the scaled feature vector (output column name)  \n",
    "`return` transformed Dataframe. The returned dataframe should have a new column named after the passed `outputColName` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94b02cdfdfd4c7d526deca26d8d717ba",
     "grade": false,
     "grade_id": "cell-0f30c6a6fc8aaaba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def scaler(df, outputColName):\n",
    "    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "\n",
    "    scalerModel = scaler.fit(df)\n",
    "\n",
    "    scaledData = scalerModel.transform(df)\n",
    "    return scaledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2cc7343e668d30bea402a6c2585cb64e",
     "grade": false,
     "grade_id": "cell-4fab9f80e65d3803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+--------------------+\n",
      "|gender| age|country|friend_count|lifetime|game1|game2|game3|game4|paid_customer|country_index|            features|      scaledFeatures|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+--------------------+\n",
      "|   1.0|23.0|    USA|         0.0|     5.0|  0.0|  1.0|  1.0|  3.0|          0.0|          0.0|[1.0,23.0,0.0,5.0...|[0.90079513989473...|\n",
      "|   1.0|20.0|     UK|         2.0|     4.0|  0.0|  0.0|  0.0|  4.0|          0.0|          1.0|[1.0,20.0,2.0,4.0...|[0.90079513989473...|\n",
      "|   1.0|24.0|     UK|         9.0|    13.0|  1.0|  0.0|  2.0| 10.0|          0.0|          1.0|[1.0,24.0,9.0,13....|[0.90079513989473...|\n",
      "|   1.0|21.0|    USA|       412.0|    80.0|  8.0|  7.0| 17.0| 48.0|          1.0|          0.0|[1.0,21.0,412.0,8...|[0.90079513989473...|\n",
      "|   1.0|20.0|    USA|         0.0|    38.0|  0.0|  3.0|  6.0| 29.0|          0.0|          0.0|[1.0,20.0,0.0,38....|[0.90079513989473...|\n",
      "|   0.0|22.0| FRANCE|        86.0|     2.0|  0.0|  2.0|  0.0|  0.0|          0.0|          3.0|[0.0,22.0,86.0,2....|[-1.1099082973702...|\n",
      "|   1.0|27.0|GERMANY|         2.0|     5.0|  1.0|  1.0|  1.0|  2.0|          0.0|          2.0|[1.0,27.0,2.0,5.0...|[0.90079513989473...|\n",
      "|   0.0|30.0|    USA|         0.0|    45.0| 19.0| 21.0|  3.0|  2.0|          0.0|          0.0|[0.0,30.0,0.0,45....|[-1.1099082973702...|\n",
      "|   0.0|26.0|GERMANY|         7.0|    20.0|  6.0|  8.0|  5.0|  1.0|          0.0|          2.0|[0.0,26.0,7.0,20....|[-1.1099082973702...|\n",
      "|   0.0|18.0|     UK|         0.0|     7.0|  5.0|  2.0|  0.0|  0.0|          0.0|          1.0|[0.0,18.0,0.0,7.0...|[-1.1099082973702...|\n",
      "|   1.0|22.0|    USA|         0.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|          0.0|(9,[0,1],[1.0,22.0])|[0.90079513989473...|\n",
      "|   1.0|24.0|GERMANY|       417.0|     1.0|  0.0|  0.0|  0.0|  1.0|          0.0|          2.0|[1.0,24.0,417.0,1...|[0.90079513989473...|\n",
      "|   0.0|21.0|    USA|         3.0|     3.0|  2.0|  1.0|  0.0|  0.0|          0.0|          0.0|[0.0,21.0,3.0,3.0...|[-1.1099082973702...|\n",
      "|   1.0|18.0|    USA|         8.0|     1.0|  0.0|  0.0|  0.0|  1.0|          0.0|          0.0|[1.0,18.0,8.0,1.0...|[0.90079513989473...|\n",
      "|   0.0|23.0|    USA|         7.0|     8.0|  4.0|  2.0|  2.0|  0.0|          0.0|          0.0|[0.0,23.0,7.0,8.0...|[-1.1099082973702...|\n",
      "|   1.0|22.0|     UK|        60.0|     8.0|  0.0|  0.0|  4.0|  4.0|          0.0|          1.0|[1.0,22.0,60.0,8....|[0.90079513989473...|\n",
      "|   1.0|18.0|    USA|         3.0|     7.0|  0.0|  2.0|  1.0|  4.0|          0.0|          0.0|[1.0,18.0,3.0,7.0...|[0.90079513989473...|\n",
      "|   0.0|20.0| CANADA|         0.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|          4.0|(9,[1,8],[20.0,4.0])|[-1.1099082973702...|\n",
      "|   1.0|22.0|    USA|         5.0|    83.0|  6.0|  9.0| 10.0| 58.0|          0.0|          0.0|[1.0,22.0,5.0,83....|[0.90079513989473...|\n",
      "|   1.0|23.0|    USA|       351.0|     5.0|  0.0|  0.0|  0.0|  5.0|          0.0|          0.0|[1.0,23.0,351.0,5...|[0.90079513989473...|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled = scaler(assembled, \"scaledFeatures\")\n",
    "scaled.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0aded1cd3159f742d0e91f298335563e",
     "grade": true,
     "grade_id": "cell-a182434c9e8c0d9c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''scaler schema test'''\n",
    "correctCols = StructType([\\\n",
    "StructField(\"gender\",DoubleType(),False),\\\n",
    "StructField(\"age\",DoubleType(),False),\\\n",
    "StructField(\"country\",StringType(),True),\\\n",
    "StructField(\"friend_count\",DoubleType(),False),\\\n",
    "StructField(\"lifetime\",DoubleType(),False),\\\n",
    "StructField(\"game1\",DoubleType(),False),\\\n",
    "StructField(\"game2\",DoubleType(),False),\\\n",
    "StructField(\"game3\",DoubleType(),False),\\\n",
    "StructField(\"game4\",DoubleType(),False),\\\n",
    "StructField(\"paid_customer\",DoubleType(),False),\\\n",
    "StructField(\"country_index\",DoubleType(),False),\\\n",
    "StructField(\"features\", VectorUDT(),True),\\\n",
    "StructField(\"scaledFeatures\", VectorUDT(),True)])\n",
    "\n",
    "fakeData = [(0.0,1.0,\"A\",1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,(Vectors.dense([1.0, 2.0])),(Vectors.dense([2.0, 0.0])))]\n",
    "\n",
    "fakeDf = spark.createDataFrame(fakeData, correctCols)\n",
    "\n",
    "assert scaled.dtypes == fakeDf.dtypes, \"the schema was expected to be %s but it was %s\" % (fakeDf.dtypes, scaled.dtypes)\n",
    "\n",
    "test4 = str(scaled.sample(False, 0.01, seed=12345).limit(1).first())\n",
    "correct4 = \"Row(gender=1.0, age=20.0, country='UK', friend_count=2.0, lifetime=4.0, game1=0.0, game2=0.0, game3=0.0, game4=4.0, paid_customer=0.0, country_index=1.0, features=DenseVector([1.0, 20.0, 2.0, 4.0, 0.0, 0.0, 0.0, 4.0, 1.0]), scaledFeatures=DenseVector([0.9008, -0.6236, -0.5183, -0.6848, -0.5844, -0.6369, -0.7638, -0.3154, -0.1343]))\"\n",
    "assert test4 == correct4, \"the row was expected to be %s but it was %s\" % (correct4, test4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dcebd2fc5755042bd160d02e53c622fb",
     "grade": false,
     "grade_id": "cell-6f316c74cc34b8db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Create Model\n",
    "`createModel` creates a Logistic Regression model. When training, 5 iterations should be enough.  \n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression\n",
    "\n",
    "param `training` transformed dataframe  \n",
    "param `featuresCol` name of the features column  \n",
    "param `labelCol` name of the label col (paid_customer)  \n",
    "param `predCol` name of the prediction col  \n",
    "`return` trained Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5b6862d42761350edf2930f992c4e1e",
     "grade": false,
     "grade_id": "cell-c8d2049a75f2e440",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def createModel(training, featuresCol, labelCol, predCol):\n",
    "    lr = LogisticRegression(maxIter = 5 , featuresCol = featuresCol ,  labelCol = labelCol , predictionCol = predCol)\n",
    "    l = lr.fit(training)\n",
    "    return l\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "526088245c3c0f3edce714f37d8acef4",
     "grade": false,
     "grade_id": "cell-25896bc1cf4ef868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#split the dataset into training(70%) and prediction(30%) sets\n",
    "splitted = scaled.randomSplit([0.7,0.3])\n",
    "\n",
    "model = createModel(splitted[0],\"scaledFeatures\",\"paid_customer\",\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2299dd1c42b7a99d76d0313987edc6e",
     "grade": false,
     "grade_id": "cell-8c4c41dcf8dd0844",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Predict\n",
    "Given a transformed and normalized dataset `predict` predicts if the customer is going to subscribe to the service.\n",
    "\n",
    "85% correct will give you 3 points (all tests pass).  \n",
    "70% correct will give you 2 points.  \n",
    "50% correct will give you 1 point.\n",
    "\n",
    "param `model` trained logistic regression model  \n",
    "param `dataToPredict` normalized dataframe for prediction  \n",
    "`return` DataFrame with predicted scores (1.0 == yes, 0.0 == no)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f523c69e48c1e43d2a68e0acfa30cc7",
     "grade": false,
     "grade_id": "cell-0f428aa47138be07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, dataToPredict):\n",
    "    d = model.transform(dataToPredict)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cae46b3425cf6af4483f33ed7955eb60",
     "grade": false,
     "grade_id": "cell-3941a4e7923325ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.59118236472945 % predicted correctly\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|gender| age|country|friend_count|lifetime|game1|game2|game3|game4|paid_customer|country_index|            features|      scaledFeatures|       rawPrediction|         probability|prediction|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|   0.0|18.0| CANADA|         9.0|    70.0| 39.0| 19.0|  9.0|  3.0|          0.0|          4.0|[0.0,18.0,9.0,70....|[-1.1099082973702...|[2.92102039130464...|[0.94887582145052...|       0.0|\n",
      "|   0.0|18.0| CANADA|        71.0|    47.0| 26.0| 11.0|  6.0|  4.0|          0.0|          4.0|[0.0,18.0,71.0,47...|[-1.1099082973702...|[3.11574873428221...|[0.95753771073695...|       0.0|\n",
      "|   0.0|18.0| CANADA|       478.0|     9.0|  4.0|  3.0|  2.0|  0.0|          0.0|          4.0|[0.0,18.0,478.0,9...|[-1.1099082973702...|[1.08104536763423...|[0.74669175847735...|       0.0|\n",
      "|   0.0|18.0|  EGYPT|         0.0|     6.0|  5.0|  0.0|  1.0|  0.0|          0.0|          6.0|[0.0,18.0,0.0,6.0...|[-1.1099082973702...|[4.63283753346764...|[0.99036658647805...|       0.0|\n",
      "|   0.0|18.0|  EGYPT|         2.0|    70.0| 37.0| 20.0|  8.0|  5.0|          0.0|          6.0|[0.0,18.0,2.0,70....|[-1.1099082973702...|[2.65319486405341...|[0.93420763139914...|       0.0|\n",
      "|   0.0|18.0|  EGYPT|         9.0|     4.0|  3.0|  0.0|  1.0|  0.0|          0.0|          6.0|[0.0,18.0,9.0,4.0...|[-1.1099082973702...|[4.60902010308183...|[0.99013667936336...|       0.0|\n",
      "|   0.0|18.0|  EGYPT|         9.0|     4.0|  3.0|  1.0|  0.0|  0.0|          0.0|          6.0|[0.0,18.0,9.0,4.0...|[-1.1099082973702...|[4.60777246747585...|[0.99012448745578...|       0.0|\n",
      "|   0.0|18.0|  EGYPT|        51.0|     6.0|  5.0|  0.0|  1.0|  0.0|          0.0|          6.0|[0.0,18.0,51.0,6....|[-1.1099082973702...|[4.23715501798281...|[0.98575715025691...|       0.0|\n",
      "|   0.0|18.0| FRANCE|         3.0|    13.0|  5.0|  4.0|  3.0|  1.0|          0.0|          3.0|[0.0,18.0,3.0,13....|[-1.1099082973702...|[4.77018718578201...|[0.99159249261204...|       0.0|\n",
      "|   0.0|18.0| FRANCE|         8.0|     8.0|  3.0|  5.0|  0.0|  0.0|          0.0|          3.0|[0.0,18.0,8.0,8.0...|[-1.1099082973702...|[4.89085408595446...|[0.99254105272209...|       0.0|\n",
      "|   0.0|18.0| FRANCE|         9.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|          3.0|(9,[1,2,8],[18.0,...|[-1.1099082973702...|[5.14350608150822...|[0.99419668689356...|       0.0|\n",
      "|   0.0|18.0| FRANCE|       334.0|    84.0| 46.0| 19.0| 16.0|  3.0|          0.0|          3.0|[0.0,18.0,334.0,8...|[-1.1099082973702...|[0.12207410801857...|[0.53048068424971...|       0.0|\n",
      "|   0.0|18.0|GERMANY|         0.0|     9.0|  6.0|  2.0|  0.0|  1.0|          0.0|          2.0|[0.0,18.0,0.0,9.0...|[-1.1099082973702...|[5.10092602012555...|[0.99394577345161...|       0.0|\n",
      "|   0.0|18.0|GERMANY|         0.0|    34.0| 15.0|  8.0|  7.0|  4.0|          0.0|          2.0|[0.0,18.0,0.0,34....|[-1.1099082973702...|[4.28308350873591...|[0.98638780502996...|       0.0|\n",
      "|   0.0|18.0|GERMANY|         0.0|    38.0| 20.0| 13.0|  3.0|  2.0|          0.0|          2.0|[0.0,18.0,0.0,38....|[-1.1099082973702...|[4.20606022337237...|[0.98531392056212...|       0.0|\n",
      "|   0.0|18.0|GERMANY|         5.0|     3.0|  2.0|  0.0|  0.0|  1.0|          0.0|          2.0|[0.0,18.0,5.0,3.0...|[-1.1099082973702...|[5.23071026137316...|[0.99467874300712...|       0.0|\n",
      "|   0.0|18.0|GERMANY|         5.0|    61.0| 33.0| 12.0| 11.0|  5.0|          0.0|          2.0|[0.0,18.0,5.0,61....|[-1.1099082973702...|[3.48833171127964...|[0.97035394151633...|       0.0|\n",
      "|   0.0|18.0|GERMANY|         9.0|     0.0|  0.0|  0.0|  0.0|  0.0|          0.0|          2.0|(9,[1,2,8],[18.0,...|[-1.1099082973702...|[5.28631969608522...|[0.99496512855394...|       0.0|\n",
      "|   0.0|18.0|GERMANY|         9.0|     4.0|  2.0|  1.0|  1.0|  0.0|          0.0|          2.0|[0.0,18.0,9.0,4.0...|[-1.1099082973702...|[5.16499958284089...|[0.99431938848184...|       0.0|\n",
      "|   0.0|18.0| MEXICO|         2.0|    77.0| 42.0| 22.0| 10.0|  3.0|          0.0|          5.0|[0.0,18.0,2.0,77....|[-1.1099082973702...|[2.61163272744158...|[0.93160650019659...|       0.0|\n",
      "+------+----+-------+------------+--------+-----+-----+-----+-----+-------------+-------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(model, splitted[1])\n",
    "correct = predictions.where(\"prediction == paid_customer\").count()\n",
    "total = predictions.count()\n",
    "print((correct / total) * 100, \"% predicted correctly\")\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "660fe4619907f303caa5cbf27faee47d",
     "grade": true,
     "grade_id": "cell-9c03a0af4edc3a65",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.74576271186442 % predicted correctly\n"
     ]
    }
   ],
   "source": [
    "'''prediction correctness test'''\n",
    "data = convert(randomData)\n",
    "data.cache()\n",
    "indexed = indexer(data)\n",
    "assembled = featureAssembler(indexed)\n",
    "scaled = scaler(assembled, \"scaledFeatures\")\n",
    "splitted = scaled.randomSplit([0.7,0.3])\n",
    "model = createModel(splitted[0],\"scaledFeatures\",\"paid_customer\",\"prediction\")\n",
    "predictions = predict(model, splitted[1])\n",
    "correct = predictions.where(\"prediction == paid_customer\").count()\n",
    "total = predictions.count()\n",
    "answer = (correct / total) * 100\n",
    "print(answer, \"% predicted correctly\")\n",
    "assert answer >= 50.0, \"less than 50% predicted correctly, you get 0 points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b24745d48b0be8e1558bb1fd7c48cd6",
     "grade": true,
     "grade_id": "cell-9f0f5384922238d8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert answer >= 70.0, \"less than 70% predicted correctly, you get 1 point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6f44b1235f0c857558491b1700c639c",
     "grade": true,
     "grade_id": "cell-2d042a867e9496e3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert answer >= 85.0, \"less than 85% predicted correctly, you get 2 points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cef00ef05113460baea465dae1e22e4b",
     "grade": false,
     "grade_id": "cell-8acd6dcad7102812",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d074b6b7a4d7b8adf89df935b7701a8c4e0af999254745575407f19f2a6d6544"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
